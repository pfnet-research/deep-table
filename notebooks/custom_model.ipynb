{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1a1ee8f-f806-4c73-83b2-6c4dfb06e276",
   "metadata": {},
   "source": [
    "# Usage example: Custom model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d75e75b-1ee0-4f3a-9c1b-5141f07464b8",
   "metadata": {},
   "source": [
    "## 1. Custom Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5a17227-c1b5-4404-8fc4-b051887649c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "\n",
    "import os,sys; sys.path.append(os.path.abspath(\"..\"))\n",
    "from deep_table.nn.encoders.embedding.base import BaseEmbedding\n",
    "\n",
    "\n",
    "class YourEmbedding(BaseEmbedding):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_continuous_features: int,\n",
    "        num_categorical_features: int,\n",
    "        num_categories: int,\n",
    "        dim_embed: int,\n",
    "        use_cls: bool = False,\n",
    "        initialization: str = \"uniform\",\n",
    "        activation = None,\n",
    "    ) -> None:\n",
    "        super().__init__(\n",
    "            num_continuous_features=num_continuous_features,\n",
    "            num_categorical_features=num_categorical_features,\n",
    "            num_categories=num_categories,\n",
    "            dim_embed=dim_embed,\n",
    "            is_in_backbone_continuous=True,\n",
    "            is_in_backbone_categorical=True,\n",
    "            dim_in_backbone=(\n",
    "                num_continuous_features + num_categorical_features,\n",
    "                dim_embed,\n",
    "            ),\n",
    "            dim_skip_backbone=0,             \n",
    "            use_cls=False,\n",
    "        )\n",
    "    \n",
    "        self.con_embed = nn.ModuleList(\n",
    "            [nn.Linear(1, dim_embed) for i in range(self.num_continuous_features)]\n",
    "        )\n",
    "        self.cat_embed = nn.Embedding(self.num_categories, dim_embed)\n",
    "\n",
    "    def continuous_embedding(self, x: Tensor) -> Tensor:\n",
    "        embedding = []\n",
    "        for i in range(len(self.con_embed)):\n",
    "            embedding.append(self.con_embed[i](x[:, i].view(-1, 1)).unsqueeze(1))\n",
    "        embedding = torch.cat(embedding, dim=1)\n",
    "        return embedding\n",
    "\n",
    "    def categorical_embedding(self, x: Tensor) -> Tensor:\n",
    "        return self.cat_embed(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eb3308-63cc-4374-8849-0842bd1c38db",
   "metadata": {},
   "source": [
    "## 2. Custom Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ab148e6-95ac-4df4-8b77-c10e08813d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_table.nn.encoders.backbone.base import BaseBackbone\n",
    "\n",
    "\n",
    "class YourBackbone(BaseBackbone):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features: int,\n",
    "        dim_embed: int,\n",
    "        use_cls: bool = True,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self._dim_out = 12\n",
    "        dim_input = num_features * dim_embed\n",
    "        self.layer = nn.Linear(dim_input, self._dim_out)\n",
    "\n",
    "    def dim_out(self, is_pretrain: bool = False) -> int:\n",
    "        return self._dim_out\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x.flatten(1)\n",
    "        x = self.layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1778c6c0-c11d-4df7-888a-5a2e1f022734",
   "metadata": {},
   "source": [
    "## 3 Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58947006-db50-4e94-b175-190b671eaf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_table.nn.models.base import BaseModel\n",
    "\n",
    "\n",
    "class YourModel(BaseModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder,\n",
    "        dim_out: int,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        self.save_hyperparameters(ignore=\"encoder\")\n",
    "        super().__init__(encoder, **kwargs)\n",
    "\n",
    "    def _build_network(self) -> None:\n",
    "        dim_representation = self.encoder.dim_out(is_pretrain=False)\n",
    "        self.mlp = nn.Linear(dim_representation, self.hparams.dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.mlp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f9e6a9-017c-4485-a360-8b09f6d7f4ba",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d80bc3a4-b422-44f2-90ac-b2de5a9376b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\n",
      "Using downloaded and verified file: ../data/Adult/raw/adult.data\n",
      "\n",
      "Downloading https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\n",
      "Using downloaded and verified file: ../data/Adult/raw/adult.test\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from deep_table.data.datasets import Adult\n",
    "from deep_table.data.data_module import TabularDatamodule\n",
    "\n",
    "\n",
    "adult_dataset = Adult(root=\"../data\")\n",
    "adult_dataframes = adult_dataset.processed_dataframes()\n",
    "\n",
    "datamodule = TabularDatamodule(\n",
    "    train=adult_dataframes[\"train\"],\n",
    "    val=adult_dataframes[\"val\"],\n",
    "    test=adult_dataframes[\"test\"],\n",
    "    task=adult_dataset.task,\n",
    "    dim_out=adult_dataset.dim_out,\n",
    "    categorical_columns=adult_dataset.categorical_columns,\n",
    "    continuous_columns=adult_dataset.continuous_columns,\n",
    "    target=adult_dataset.target_columns,\n",
    "    num_categories=adult_dataset.num_categories,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b041848-6685-4c6d-86f7-97ef7fb9d7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "\n",
    "# Encoder settings\n",
    "encoder_config = OmegaConf.create({\n",
    "    \"embedding\": {\n",
    "        \"args\": {\n",
    "            \"dim_embed\": 16\n",
    "        }\n",
    "    },\n",
    "    \"backbone\": {\n",
    "        \"args\": {}\n",
    "    }\n",
    "})\n",
    "\n",
    "# model settings (learning rate, scheduler...)\n",
    "model_config = OmegaConf.create({\n",
    "    \"args\": {}\n",
    "})\n",
    "\n",
    "# training settings (epoch, gpu...)\n",
    "trainer_config = OmegaConf.create({\n",
    "    \"gpus\": 0,\n",
    "    \"max_epochs\": 1,\n",
    "    \"seed\": 42\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "194007a1-ebed-469d-8607-8fb5474b259d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/home/tsumli/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1294: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 42\n",
      "\n",
      "  | Name    | Type              | Params\n",
      "----------------------------------------------\n",
      "0 | encoder | Encoder           | 4.7 K \n",
      "1 | mlp     | Linear            | 13    \n",
      "2 | loss    | BCEWithLogitsLoss | 0     \n",
      "----------------------------------------------\n",
      "4.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.7 K     Total params\n",
      "0.019     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05d0cbdb8b546348056b2f5163f5b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dab4e94a4e84430b81fa32e2069b959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 191it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deep_table.estimators.base import Estimator\n",
    "from deep_table.utils import get_scores\n",
    "\n",
    "estimator = Estimator(\n",
    "    encoder_config, model_config, trainer_config,\n",
    "    custom_embedding=YourEmbedding, custom_backbone=YourBackbone, custom_model=YourModel\n",
    ")\n",
    "estimator.fit(datamodule)\n",
    "\n",
    "predict = estimator.predict(datamodule.dataloader(split=\"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f368c33-cc96-4d7a-b6dd-f748f3944b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.847613782937166,\n",
       " 'AUC': 0.902428561959527,\n",
       " 'F1 score': 0.9039823522582143,\n",
       " 'cross_entropy': 0.3242064072908491}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_scores(predict, target=datamodule.dataloader(split=\"test\"), task=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc775238-5aa8-4198-87ef-1d8cc93ebe06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570336d4-7006-494e-8c93-c352fa399a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
